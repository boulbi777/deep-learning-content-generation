{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quelques exemples de génération d'article\n",
    "\n",
    "### Auteur : Boubacar TRAORE, System : Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    \n",
       "    .rendered_html {\n",
       "         font-size: 22px; \n",
       "         font-family: Garamond;\n",
       "         line-height: 140%;\n",
       "         text-align: justify;\n",
       "         text-justify: inter-word;\n",
       "    }\n",
       "\n",
       "    div.text_cell_render h1 { /* Main titles bigger, centered */\n",
       "        text-align:center;\n",
       "    # }\n",
       "    \n",
       "    </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Changement de la police utilisée et de sa taille\n",
    "from IPython.core.display import HTML, display\n",
    "from style import change_font\n",
    "display(HTML(change_font()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n)\n",
       "        a += \"    \";\n",
       "    return a;\n",
       "}\n",
       "// look up into all sections and builds an automated menu //\n",
       "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i,t;\n",
       "    var text_menu = begin;\n",
       "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    var tags = [];\n",
       "    var main_item = 0;\n",
       "    var format_open = 0;\n",
       "    for (i = 0; i <= llast; i++)\n",
       "        tags.push(\"h\" + i);\n",
       "\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
       "\n",
       "        var child = null;\n",
       "        for(t = 0; t < tags.length; t++) {\n",
       "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
       "            if (r.length > 0) {\n",
       "child = r[0];\n",
       "break;\n",
       "            }\n",
       "        }\n",
       "        if (child == null) {\n",
       "            text_memo += \"null\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            // when converted in RST\n",
       "            href = anchors[i].id;\n",
       "            text_memo += \"#1-\" + href;\n",
       "            // passer à child suivant (le chercher)\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            // in a notebook\n",
       "            href = child.id;\n",
       "            text_memo += \"#2-\" + href;\n",
       "        }\n",
       "        else {\n",
       "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "\n",
       "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
       "\n",
       "        if ((level < lfirst) || (level > llast)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
       "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
       "        }\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        while (level < memo_level) {\n",
       "            text_menu += end_format + \"</ul>\\n\";\n",
       "            format_open -= 1;\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        if (level == lfirst) {\n",
       "            main_item += 1;\n",
       "        }\n",
       "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
       "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2);\n",
       "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
       "        format_open += 1;\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += end_format + \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    text_menu += send;\n",
       "    //text_menu += \"\\n\" + text_memo;\n",
       "\n",
       "    while (format_open > 0) {\n",
       "        text_menu += end_format;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    return text_menu;\n",
       "};\n",
       "var update_menu = function() {\n",
       "    var sbegin = \"\";\n",
       "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
       "    var send = \"\";\n",
       "    var begin_format = '<li>';\n",
       "    var end_format = '</li>';\n",
       "    var keep_item = -1;\n",
       "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
       "       begin_format, end_format);\n",
       "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajout du sommaire\n",
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des libraries nécessaires\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous nous proposons d'énumérer différentes manières de générer des articles, soit à partir de notre propre corpus (collection de documents d'anciens articles que nous possédons déjà comme base d'entrainement de notre modèle), soit à partir de modèles préentrainés sur un corpus beaucoup plus large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Préparation des articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les articles que nous utilisons dans cette étude proviennent de l'agence de presse Reuters (https://fr.wikipedia.org/wiki/Reuters). Ces données ont été collectées en 2005. Il s'agit d'un dossier contenant 2500 articles d'actualité (newspaper) venant de 50 auteurs différents. Ces articles sont stockés dans le dossier \"**data**\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des répertoires où sont stockées nos données\n",
    "data_dir = 'data'   # Spécification du dossier contenant les articles à parser\n",
    "cwd = os.getcwd() + \"/\" + data_dir # cwd contient le chemin d'accès vers le dossier 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons parcourir tous les articles qui se trouvent dans les dossiers nommés d'après leurs auteurs. Pour cela, nous créons deux listes. La première nommée \"documents_infos\" qui va contenir les informations disponibles de chaque article (titre et nom de l'auteur) sous forme de dictionnaire et la seconde liste nommée \"documents\" contient le corps de chaque article stockée sous format texte (str). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_infos, documents  = [], []\n",
    "for folder in os.listdir(cwd):\n",
    "    for file in os.listdir(cwd + \"/\" + folder):\n",
    "        with open(data_dir + '/' + folder + '/' + file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            infos = {'title': lines[0].strip(), 'author': folder}\n",
    "            documents_infos.append(infos)\n",
    "            documents.append(''.join(lines[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons identifié 2500 articles. Essayons maintenant d'afficher le contenu (limité aux 500 premiers caractères) et les informations d'un article aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(777)\n",
    "id_doc = np.random.randint(0,len(documents),1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Fallout from a scandal involving late allocation of trades at Jardine Fleming was still attracting attention in Hong Kong on Wednesday, but the company escaped further sanctions and said business continued as usual.',\n",
       " 'author': 'SarahDavison'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_infos[id_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We've had some redemptions. We've also had some subscriptions,\" a company spokesman told Reuters. \"The business pattern is very much as usual.\"\n",
      "Jardine Fleming retained its seat on the executive committee of the domestic industry association, the Hong Kong Investment Funds Association, despite media reports that moves were afoot to knock the company off the committee.\n",
      "In election results released on Wednesday, Jardine Fleming continues as one of 12 member firms with a representative on the boar....\n"
     ]
    }
   ],
   "source": [
    "print(documents[id_doc][:500] + '....')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les articles sont bien stockés. Passons aux différentes méthodes de modélisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Un modèle basique & simple : les chaînes de Markov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les chaines de Markov est un processus permettant de prédire un évènement suivant en se basant sur l'évènement qui vient tout juste de se réaliser. On dit qu'il s'agit d'un modèle à courte mémoire car toute l'information nécessaire pour prédire le futur est disponible dans le présent et indépendante du futur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les chaines de Markov peuvent bien être adaptés dans notre cas puisque la génération d'article démarre d'une expression donnée par l'utilisateur, le modèle va donc à chaque fois tenter de deviner le mot suivant à partir du précédent donné. Pour celà, nous pouvons fusionner tous les contenus des articles en un seul grand texte et créer un dictionnaire de mots, qui, à chaque clé (mot), associe la liste des mots qui le suivent dans tout le corpus. Il suffit donc de compter l'occurence de chaque mot dans cette liste pour calculer les probabilités de transition d'un mot à un autre dans le texte. Ainsi, il très facile de générer un nouveau texte (ou article) à partir de ces probabilités de transition. \n",
    "\n",
    "La vidéo suivante explique très bien comment procéder facilement de A à Z à la création d'une chaine markov pour notre corpus d'articles : https://www.youtube.com/watch?v=MGVdu39gT6k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Pros and Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pros* :\n",
    "   * Il s'agit d'un modèle très simple et facile à implémenter (basé essentiellement sur comptage de mots)\n",
    "   * Le temps d'entrainement est négligeable\n",
    "\n",
    "\n",
    "*Cons* :\n",
    "   * Très peu performant, car peut facilement générer un texte dépourvu de sens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Des réseaux de neurones basiques : le LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De son nom complet \"**Long Short Term Memory**\", il s'agit d'un réseau de neurone réccurrent en deep learning (les connexions entre les neurones sont réccurents) très utilisé dans les études de series temporelles pour faire de la prévision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Cas de la génération d'articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme dans le cas des chaines de Markov vus précédemment, le LSTM est très bien adapté à ce type de problème puisqu'elle fait aussi de la prédiction de lettre suivante à partir des précédentes. Il existe une énorme quantité de documents, de repositories git, d'articles sur le LSTM en ligne (il y en a vraiment beaucoup, on peut facilement trouver du contenu intéressant selon notre besoin). Un des articles qui pourrait nous aider : https://www.analyticsvidhya.com/blog/2018/03/text-generation-using-python-nlp/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Pros et Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pros* :\n",
    "   * C'est un modèle extrêment personnalisable, plusieurs paramètres à tuner...\n",
    "   * Les performances peuvent être nettement mieux comparé à celle d'une chaine de markov si jamais la phase d'entrainement bien faite\n",
    "   * Possibilité d'utilisé des modèles préentrainés\n",
    "\n",
    "\n",
    "*Cons* :\n",
    "   * Peut prendre du temps si on veut entrainer son propre corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Un nouvel état de l'art du NLP : le GPT-2 de OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le traitement de langage naturel reste en constante innovation. Le modèle GPT-2 de OpenAI a récemment éclaté les performances en terme de génération automatique de texte, le tout avec une rapidité et une efficacité hors norme. Plusieurs articles et vidéos sont disponibles pour expliquer l'architecture et le fonctionnement de GPT-2 qui utilise des *transformers* comme réseau de neurone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Du transfert learning pour la génération d'articles similaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs versions préentrainés de GPT-2 existent, seules deux versions ont été publiées. Il est possible d'utiliser l'une des deux versions pour faire du transfer learning (apprentissage par transfert consistant à utiliser une majeure partie des poids présents dans le réseau déjà entrainé en réajustant les poids de certaines couches finales à un dataset particulier) en utilisant les textes des articles que nous avons dans ce notebook. Pour faire celà, il y a un excellent article : https://minimaxir.com/2019/09/howto-gpt2/\n",
    "\n",
    "L'éxécution de bout en bout de cet article nécessitant plusieurs fonctionnalités non disponibles en local dans \"jupyter\", j'ai préféré me limiter à la bonne compréhension de ce dernier qui peut facilement être réadapté à notre contexte. Il présente la particularité de pouvoir bien choisir son corpus en l'incluant dans la phase d'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Utilisation directe d'un modèle GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible d'utiliser directement un modèle GPT-2 publié par OpenAI pour faire de la prédiction. On peut alors changer les paramètres du modèle préentrainé à notre guise (length, temperature, top_k, sont des paramètres que nous pouvons changer nous même) avec le déjà utilisé par GPT-2. Il n'est pas garanti que les résultats soient satisfaisantes, mais comme GPT-2 a été entrainé sur des millions de pages web scrappées, il est bien probable que le contenu généré soit de très bonne qualité. Voici un article intéressant si cette méthode nous intéresse : https://www.analyticsvidhya.com/blog/2019/07/openai-gpt2-text-generator-python/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
